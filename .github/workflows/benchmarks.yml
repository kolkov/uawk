name: Benchmark Comparison

# Benchmark Comparison Strategy:
# - Runs only on PRs to main (most impactful)
# - Compares PR benchmarks with base branch using benchstat
# - Posts results as PR comment (informational, not blocking)
# - Uses 5 iterations for reasonable CI time vs statistical significance
#
# Note: GitHub Actions shared runners have ~10-20% variance.
# Results are directional, not absolute. Major regressions (>30%) are reliable.

on:
  pull_request:
    branches:
      - main

permissions:
  contents: read
  pull-requests: write

jobs:
  benchmark-compare:
    name: Benchmark Comparison
    runs-on: ubuntu-latest
    # Don't run on draft PRs
    if: github.event.pull_request.draft == false

    steps:
    - name: Checkout PR branch
      uses: actions/checkout@v4
      with:
        ref: ${{ github.event.pull_request.head.sha }}
        path: pr

    - name: Checkout base branch
      uses: actions/checkout@v4
      with:
        ref: ${{ github.event.pull_request.base.sha }}
        path: base

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.25'
        cache: false  # Different directories, cache won't help

    - name: Install benchstat
      run: go install golang.org/x/perf/cmd/benchstat@latest

    - name: Run base branch benchmarks
      working-directory: base
      run: |
        echo "# Base branch benchmarks - ${{ github.event.pull_request.base.sha }}" > ../base-bench.txt
        echo "# Generated: $(date -Iseconds)" >> ../base-bench.txt
        echo "" >> ../base-bench.txt

        # Run critical benchmarks (5 iterations for CI speed)
        go test -bench=. -benchmem -count=5 -benchtime=50ms ./internal/vm/... 2>/dev/null >> ../base-bench.txt || true
        go test -bench=. -benchmem -count=5 -benchtime=50ms ./internal/lexer/... 2>/dev/null >> ../base-bench.txt || true
        go test -bench=. -benchmem -count=5 -benchtime=50ms ./internal/parser/... 2>/dev/null >> ../base-bench.txt || true

    - name: Run PR branch benchmarks
      working-directory: pr
      run: |
        echo "# PR branch benchmarks - ${{ github.event.pull_request.head.sha }}" > ../pr-bench.txt
        echo "# Generated: $(date -Iseconds)" >> ../pr-bench.txt
        echo "" >> ../pr-bench.txt

        # Run same benchmarks on PR
        go test -bench=. -benchmem -count=5 -benchtime=50ms ./internal/vm/... 2>/dev/null >> ../pr-bench.txt || true
        go test -bench=. -benchmem -count=5 -benchtime=50ms ./internal/lexer/... 2>/dev/null >> ../pr-bench.txt || true
        go test -bench=. -benchmem -count=5 -benchtime=50ms ./internal/parser/... 2>/dev/null >> ../pr-bench.txt || true

    - name: Compare benchmarks
      id: benchstat
      run: |
        # Full benchstat output to file (for artifact)
        benchstat base-bench.txt pr-bench.txt > full-comparison.txt 2>&1 || echo "benchstat comparison failed" > full-comparison.txt

        # Extract summary (geomean line) and check for regressions
        GEOMEAN=$(grep -E "^geomean" full-comparison.txt | head -1 || echo "")
        REGRESSIONS=$(grep -E "\+[0-9]+\.[0-9]+%" full-comparison.txt | grep -v "~" | head -10 || echo "")

        # Build concise PR comment
        echo "## Benchmark Comparison" > comparison.md
        echo "" >> comparison.md
        echo "Comparing \`${{ github.event.pull_request.base.ref }}\` → PR #${{ github.event.pull_request.number }}" >> comparison.md
        echo "" >> comparison.md

        if [ -n "$GEOMEAN" ]; then
          echo "**Summary:** \`$GEOMEAN\`" >> comparison.md
          echo "" >> comparison.md
        fi

        if [ -n "$REGRESSIONS" ]; then
          echo "⚠️ **Potential regressions detected:**" >> comparison.md
          echo "\`\`\`" >> comparison.md
          echo "$REGRESSIONS" >> comparison.md
          echo "\`\`\`" >> comparison.md
          echo "" >> comparison.md
        else
          echo "✅ No significant regressions detected." >> comparison.md
          echo "" >> comparison.md
        fi

        echo "> Full results available in workflow artifacts. CI runners have ~10-20% variance." >> comparison.md
        echo "> For accurate benchmarks, run locally: \`bash scripts/pre-release-check.sh\`" >> comparison.md

        cat comparison.md

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-comparison
        path: |
          base-bench.txt
          pr-bench.txt
          full-comparison.txt
        retention-days: 30

    - name: Find existing comment
      uses: peter-evans/find-comment@v3
      id: fc
      with:
        issue-number: ${{ github.event.pull_request.number }}
        comment-author: 'github-actions[bot]'
        body-includes: '## Benchmark Comparison'

    - name: Create or update comment
      uses: peter-evans/create-or-update-comment@v4
      with:
        comment-id: ${{ steps.fc.outputs.comment-id }}
        issue-number: ${{ github.event.pull_request.number }}
        body-path: comparison.md
        edit-mode: replace
